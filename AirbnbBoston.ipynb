{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb Boston Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "1. What are the most expensive neighbourhoods in Boston?\n",
    "2. Is there a price-sesonality?\n",
    "3. Based on the reviews, are there months where people prefere to visit boston?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "df_calendar = pd.read_csv('./calendar.csv')\n",
    "df_listings = pd.read_csv('./listings.csv', index_col='id')\n",
    "df_reviews = pd.read_csv('./reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove '$' and ',' from price and convert price into float\n",
    "df_calendar['price'] = df_calendar['price'].str.replace('$','')\n",
    "df_calendar['price'] = df_calendar['price'].str.replace(',','')\n",
    "df_calendar['price'] = df_calendar['price'].astype(float)\n",
    "\n",
    "# convert date from dtype 'object' to 'date\n",
    "df_calendar['date'] = pd.to_datetime(df_calendar['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share of days for which no price is available\n",
    "print(\"The share of days for which the listings are unavailable is {}\".format(df_calendar['price'].isnull().sum()/df_calendar.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with the calendar price data, transform the data to a pivot table. **Listings for which there is no price at all available, are dropped.** Henceforth, only listings which have at least one price available are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfor the calendar data into a more convenient layout\n",
    "df_price = df_calendar.pivot_table(index='date',columns='listing_id',values='price')\n",
    "\n",
    "# relevant listings\n",
    "listings = df_price.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The share of listings for which there is no variability in the price is {}\".format((df_price.std()==0).sum()/df_price.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolate linearly for missing values, for values at the beginning of the period use a backwardfill \n",
    "df_price = df_price.interpolate(method='linear').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listing_mean_neighbourhood(listing_id):\n",
    "    neighbourhood = df_listings.loc[listing_id]['neighbourhood_cleansed']\n",
    "    mean_price = df_price[listing_id].mean()\n",
    "\n",
    "    return neighbourhood, mean_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "for listing in listings:\n",
    "    neighbourhood, mean_price = listing_mean_neighbourhood(listing)\n",
    "    d.append(\n",
    "        {\n",
    "            'listing_id':listing,\n",
    "            'neighbourhood': neighbourhood,\n",
    "            'mean_price': mean_price\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_listing_mean_neighbourhood = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price_by_neighbourhood = df_listing_mean_neighbourhood[['neighbourhood','mean_price']].groupby('neighbourhood').mean().sort_values(by='mean_price')\n",
    "mean_price_by_neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = mean_price_by_neighbourhood.plot.bar(layout='constraint')\n",
    "\n",
    "plt.title('Mean Aribnb Price per Neigbourhood in Boston (MA)')\n",
    "plt.savefig('mean_price_neighbor.jpeg',bbox_inches=\"tight\",dpi=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_price.mean(axis=1).plot(layout='constraint')\n",
    "\n",
    "plt.title('Mean Airbnb Price per Night in Boston (MA)')\n",
    "plt.savefig('mean_price_per_night.jpeg',bbox_inches=\"tight\",dpi=600);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adressing question #3 is more complex than questions #1 & #2. The goal is to use features of the listing (type, rooms, neigborhood, ...) and reviews (no. of reviews per listing, frequency of reviews, ...) to predict the price of a given listing on the day the `listings.csv` data has beeen scraped. To start modeling we have to decide on features we want to include in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings_red = df_listings[[\n",
    "                    'last_scraped',\n",
    "                    'host_since',\n",
    "                    'host_response_time',\n",
    "                    'host_response_rate',\n",
    "                    'host_acceptance_rate',\n",
    "                    'host_is_superhost',\n",
    "                    'host_listings_count',\n",
    "                    'host_has_profile_pic',\n",
    "                    'host_identity_verified',\n",
    "                    'neighbourhood_cleansed',\n",
    "                    'property_type',\n",
    "                    'room_type',\n",
    "                    'accommodates',\n",
    "                    'bathrooms',\n",
    "                    'bedrooms',\n",
    "                    'beds',\n",
    "                    'bed_type',\n",
    "                    'amenities',\n",
    "                    'price',\n",
    "                    'cleaning_fee',\n",
    "                    'guests_included',\n",
    "                    'minimum_nights',\n",
    "                    'review_scores_rating',\n",
    "                    'review_scores_accuracy',\n",
    "                    'review_scores_cleanliness',\n",
    "                    'review_scores_checkin',\n",
    "                    'review_scores_communication',\n",
    "                    'review_scores_location',\n",
    "                    'review_scores_value',\n",
    "                    'cancellation_policy',\n",
    "                    'reviews_per_month']].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to prepare the columns that are in the wrong format, e.g., turn host_since into the date difference relative to 2016-09-07 in days, and convert numbers with '$' or '%' sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert last_scraped and host_since to datetime\n",
    "df_listings_red[['last_scraped','host_since']] = df_listings_red[['last_scraped','host_since']].apply(pd.to_datetime)\n",
    "\n",
    "#calculate host_since in days\n",
    "df_listings_red['host_since_days'] = (df_listings_red['last_scraped'] - df_listings_red['host_since']) / np.timedelta64(1, 'D')\n",
    "\n",
    "# drop 'last_scraped','host_since'\n",
    "\n",
    "df_listings_red = df_listings_red.drop(['last_scraped','host_since'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove % sign from rate columns and convert them to dtype float\n",
    "def convert_rate(df: pd.DataFrame, cols: list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Remove '%' sign and convert column to float between 0 and 1\n",
    "    # Parameters\n",
    "    df:     dataframe of interest\n",
    "    cols:   list of columns which feature rates\n",
    "    \"\"\"\n",
    "\n",
    "    for col in cols:\n",
    "        df[col] = df[col].str.replace('%','')\n",
    "        df[col] = df[col].astype(float)/100\n",
    "\n",
    "#remove $ sign and , as seperator and turn dollar amount columns into float\n",
    "def convert_dollar(df: pd.DataFrame, cols: list):\n",
    "\n",
    "    \"\"\"\n",
    "    Remove '$' and ',' sign and convert column to float\n",
    "    # Parameters\n",
    "    df:     dataframe of interest\n",
    "    cols:   list of columns which feature rates\n",
    "    \"\"\"\n",
    "\n",
    "    for col in cols:\n",
    "        df[col] = df[col].str.replace('$','')\n",
    "        df[col] = df[col].str.replace(',','')\n",
    "        df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_rate(df_listings_red,['host_response_rate', 'host_acceptance_rate'])\n",
    "convert_dollar(df_listings_red,['price', 'cleaning_fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings_red_amen = df_listings_red[['amenities']].copy()\n",
    "df_listings_red_amen['amenities'] = df_listings_red_amen['amenities'].str.replace('{','')\n",
    "df_listings_red_amen['amenities'] = df_listings_red_amen['amenities'].str.replace('}','')\n",
    "df_listings_red_amen['amenities'] = df_listings_red_amen['amenities'].str.replace('\"','')\n",
    "\n",
    "df_amenities = df_listings_red_amen['amenities'].str.split(',',expand=True)\n",
    "df_amenities\n",
    "\n",
    "df_amenities[0].unique()\n",
    "\n",
    "l=[]\n",
    "\n",
    "for col in df_amenities.columns:\n",
    "    for amen in df_amenities[col].unique():\n",
    "        l.append(amen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = list(set(l))\n",
    "amenities.remove('')\n",
    "amenities.remove(None)\n",
    "amenities.remove('translation missing: en.hosting_amenity_49')\n",
    "amenities.remove('translation missing: en.hosting_amenity_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "for id in df_listings_red.index:\n",
    "    l2 = []\n",
    "    for amen in amenities:\n",
    "        if amen in list(df_amenities.loc[id]):\n",
    "            l2.append(1)\n",
    "        else:\n",
    "            l2.append(0)\n",
    "    l1.append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amen_cat = pd.DataFrame(index=df_listings_red.index, columns=amenities, data=l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings_red = pd.merge(df_listings_red, df_amen_cat, left_index=True,right_index=True).drop('amenities',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for listings where cleaning_fee is missing replace NaN with 0 because probably no fee due\n",
    "df_listings_red[['cleaning_fee']] = df_listings_red[['cleaning_fee']].fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All variables which require special consideradtion regarding data preparation have been dealt with\n",
    "- Now, for all numerical variables which have missing values at this point, we'll simpy impute them using the mean of the features column\n",
    "- For the remaining categorcial variables we'll create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings_red_cat = df_listings_red.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a copy of the dataframe\n",
    "df_listings_red_cat_copy = df_listings_red_cat.copy()\n",
    "#Pull a list of the column names of the categorical variables\n",
    "df_listings_red_cat_lst = df_listings_red_cat.columns\n",
    "\n",
    "def create_dummy_df(df, cat_cols, dummy_na):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics:\n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "    '''\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        try:\n",
    "            # for each cat add dummy var, drop original column\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True, dummy_na=dummy_na)], axis=1)\n",
    "        except:\n",
    "            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fit_linear_mod(df, response_col, cat_cols, dummy_na, test_size=.3, rand_state=42):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - a dataframe holding all the variables of interest\n",
    "    response_col - a string holding the name of the column \n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    test_size - a float between [0,1] about what proportion of data should be in the test dataset\n",
    "    rand_state - an int that is provided as the random state for splitting the data into training and test \n",
    "    \n",
    "    OUTPUT:\n",
    "    test_score - float - r2 score on the test data\n",
    "    train_score - float - r2 score on the test data\n",
    "    lm_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model \n",
    "    '''\n",
    "    \n",
    "    #drop rows with missing response values\n",
    "    df = df.dropna(axis=0, subset=[response_col])\n",
    "    \n",
    "    #drop columns where all values are missing\n",
    "    df = df.dropna(axis=1,how='all')\n",
    "    \n",
    "    #dummy categorical variables\n",
    "    df = create_dummy_df(df, cat_cols, dummy_na)\n",
    "    \n",
    "    #mean function\n",
    "    fill_mean = lambda col: col.fillna(col.mean())\n",
    "\n",
    "    #fill mean for missing values\n",
    "    df = df.apply(fill_mean,axis=0)\n",
    "    \n",
    "    #split data\n",
    "    X = df.drop(response_col,axis=1)\n",
    "    y = df[response_col]\n",
    "    \n",
    "    #training and test data sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=rand_state)\n",
    "    \n",
    "    #instantiate linear regression model\n",
    "    lm_model = LinearRegression()\n",
    "    \n",
    "    #fit model\n",
    "    lm_model.fit(X_train,y_train)\n",
    "    \n",
    "    #predict response for train and test data\n",
    "    y_train_preds = lm_model.predict(X_train)\n",
    "    y_test_preds = lm_model.predict(X_test)\n",
    "    \n",
    "    #rsquare for train and test data\n",
    "    train_score = r2_score(y_train,y_train_preds)\n",
    "    test_score = r2_score(y_test, y_test_preds)\n",
    "\n",
    "    return test_score, train_score, lm_model, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score, train_score, lm_model, X_train, X_test, y_train, y_test = clean_fit_linear_mod(df_listings_red, 'price', df_listings_red_cat_lst, dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The rsquared on the training data was {}.  The rsquared on the test data was {}.\".format(train_score, test_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Dec  1 2022, 15:52:24) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "528a34026aacc80e3fdcec18b7e636f847892d5ab0d86d58c28dbcf772c3c326"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
